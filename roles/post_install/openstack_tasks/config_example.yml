### Run triggers
setup_os_env: true
user: true
quota: true
volume: true
network: true
net_port: true
aggregate: true
flavor: true
image: true
keypair: true
security_group: true
instance: true
overcloud_delete: false
resources_output: true

# Whether or not SSL API requests should be verified.
validate_certs: true

# Set the state of the resource.
# The state could be 'present' or 'absent'.
resource_state: present

# The name of the "cloud", the tasks should be run on.
# The "cloud" represents a stack (undercloud/overcloud), or a user that the playbook should interact with.
# All "clouds" configuration resides within the "~/.config/openstack/clouds.yaml" file.
# A different cloud name could be set on each resource.
# As a result multiple users resources could be created at a single playbook run.
cloud_name: overcloud

# Custom quotas could be defined for each user during the user creation.
users:
  - name: nfv_user1
    pass: nfv_user1
    project: nfv_user1
    domain: default
    role: member
    quota:
      - cores: 20
        ram: 20480
        instances: 25
  - name: nfv_user2
    pass: nfv_user2
    project: nfv_user2
    domain: default
    role: member

# Volumes
# Populate OpenStack Cinder volumes
# Scheduler hints may be used in order to assist scheduler, available hints:
#   - 'same_host': Create volume on the same host where the instance is located at.
#                  It is required to provide an hypervisor ID but this is not intuitive
#                  since the ID is unique and generated during deployment.
#                  We expect the user to provide the FQDN of the hypervisor, and the play
#                  will attempt to discover the correct ID.
volumes:
  - name: 'os_volume_1'
    cloud_name: 'overcloud'
    availability_zone: 'nova'
    size: 1
  - name: 'os_volume_2'
    cloud: 'overcloud'
    availability_zone: 'nova'
    size: 1
    scheduler_hints:
      same_host: 'computeovsdpdksriov-0'

# Networks
# Define the networks that should be created on the overcloud.
# 'External: true' value could be defined just for the external network.
# 'External: false' is a must for tenant mgmt network to be connected with External: true net.
# Allocation pools could be defined as an option in case specific pool range should be defined.
# Otherwise, pool will be calculated by 'cidr' value.
# 'network_type' and 'ip_version' arguments could be defined as an option.
# By default, 'network_type' uses 'vlan', 'ip_version' uses 'ipv4'
# 'gateway_ip' could be defined in case there is a need to specify gateway ip address.
# 'shared', define whether this network is shared or not.
# 'cloud_name' define which cloud user create the resources.
# In case of resources_output exist, access network should be duplicated.
# for public overcloud, admin, and router of tenant cloud, ex. nfv_user1
networks:
  - name: 'access'
    cloud_name: nfv_user1
    physical_network: 'access'
    segmentation_id: '25'
    allocation_pool_start: '10.35.141.113'
    allocation_pool_end: '10.35.141.125'
    cidr: '10.35.141.112/28'
    enable_dhcp: true
    gateway_ip: '10.35.141.126'
    network_type: vlan
    external: true
    shared: true
    router_name: router1
# This tenant network connected through router to access network
  - name: 'dpdk-mgmt'
    cloud_name: nfv_user1
    allocation_pool_start: '10.10.110.100'
    allocation_pool_end: '10.10.110.200'
    cidr: '10.10.110.0/24'
    enable_dhcp: true
    gateway_ip: '10.10.110.254'
    network_type: vxlan
    external: false
    router_name: router1

  - name: 'sriov-1'
    allocation_pool_start: '40.0.0.100'
    allocation_pool_end: '40.0.0.200'
    physical_network: sriov-1
    cidr: '40.0.0.0/24'
    enable_dhcp: false
    gateway_ip: '40.0.0.254'
    network_type: vlan

  - name: 'sriov-2'
    allocation_pool_start: '50.0.0.100'
    allocation_pool_end: '50.0.0.200'
    physical_network: sriov-2
    cidr: '50.0.0.0/24'
    enable_dhcp: false
    gateway_ip: '50.0.0.254'
    network_type: vlan

dns_nameservers:
  - 8.8.8.8
  - 8.8.4.4

# Aggregation groups with the hosts that should be attached
# and custom metadata.
aggregate_groups:
  - name: host0
    hosts: computeovsdpdksriov-0.localdomain
    metadata:
      - flavor=host0

# Define the flavors that should be created.
# Multiple "extra_specs" could be defined.
flavors:
  - name: m1.medium.huge_pages
    ram: 8192
    disk: 20
    vcpus: 6
    extra_specs:
      "hw:mem_page_size": "1GB"
      "hw:cpu_policy": "dedicated"
      "hw:emulator_threads_policy": "share"
      "aggregate_instance_extra_specs:flavor": "host0"

# Images to upload
images:
  - name: centos7
    url: http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2

# The keypair that will be used by the instances.
keypairs:
  - name: test_keypair
    cloud_name: nfv_user1

security_groups:
  - name: test_secgroup
    cloud_name: nfv_user1
    rules:
      - protocol: icmp
        port_range_min: -1
        port_range_max: -1
        remote_ip_prefix: 0.0.0.0/0
      - protocol: tcp
        port_range_min: 22
        port_range_max: 22
        remote_ip_prefix: 0.0.0.0/0

instances:
  - name: vm1
    cloud_name: nfv_user1
    groups:
      - vm_groups
      - group1
    flavor: m1.medium.huge_pages
    image: centos7
    key_name: test_keypair
    sec_groups: test_secgroup
    floating_ip:
      ext_net: access
      int_net: dpdk-mgmt
    # The nics attached to the instance could be a created ports specified below,
    # or just a network name. Note the port-name and net-name.
    nics:
      - port-name=dpdk-mgmt_port1
      - port-name=sriov-1_port1
    net_ports:
      - name: dpdk-mgmt_port1
        network: dpdk-mgmt
        type: normal
        sec_groups: test_secgroup
      - name: sriov-1_port1
        network: sriov-1
        type: direct
        port_security: false
  - name: vm2
    cloud_name: nfv_user1
    groups:
      - vm_groups
      - group2
    flavor: m1.medium.huge_pages
    image: centos7
    key_name: test_keypair
    sec_groups: test_secgroup
    floating_ip:
      ext_net: access
      int_net: dpdk-mgmt
    nics:
      - port-name=dpdk-mgmt_port2
      - port-name=sriov-2_port1
    net_ports:
      - name: dpdk-mgmt_port2
        network: dpdk-mgmt
        type: normal
        sec_groups: test_secgroup
      - name: sriov-2_port1
        network: sriov-2
        type: direct
        port_security: false
  - name: vm3
    groups:
      - vm_groups
    flavor: m1.medium.huge_pages
    image: centos7
    key_name: test_keypair
    sec_groups: test_secgroup
    floating_ip:
      ext_net: access
      int_net: dpdk_mgmt
    nics:
      - net-name=dpdk-mgmt
      - port-name=sriov-1_port2
    net_ports:
      - name: sriov-1_port2
        network: sriov-1
        type: direct
        port_security: false
  - name: vm4
    groups: hci
    flavor: m1.medium.huge_pages
    image: centos7
    key_name: test_keypair
    sec_groups: test_secgroup
    config_drive: true
    volumes:
      - 'os_volume_1'
      - 'os_volume_2'
    nics:
      - net-name=management_net_numa1_114
    floating_ip:
      ext_net: external_net_numa1_419
      int_net: management_net_numa1_114

# The path to the file output of the created resources.
resources_output_file: /home/stack/resources_output_file.yml
